# -*- coding: utf-8 -*-
# Anonimizacao_Colab (1).ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/17028G4jQfu6R8r7M9N7znLX-MrzQcdnG

# AP – Pré‑Processamento de Dados: **Anonimização** (Colab)
# *Versão guia passo‑a‑passo* — gerado em 2025-10-28 18:23


!pip -q install pandas numpy faker text-anonymizer pyarrow scikit-learn

# Importações e semente aleatória

import os, hmac, hashlib, json
import numpy as np
import pandas as pd
from faker import Faker

# text-anonymizer tem duas APIs comuns; tratamos ambos os casos:
try:
    from text_anonymizer import Anonymizer
    _anonymizer_mode = "class"
except Exception:
    try:
        from text_anonymizer import anonymize as _anonymize_fn
        _anonymizer_mode = "function"
    except Exception:
        _anonymizer_mode = None

# Reprodutibilidade:
RANDOM_SEED = 42
rng = np.random.default_rng(RANDOM_SEED)
fake = Faker("pt_BR")
Faker.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

print("Sucesso: imports concluídos. Modo text_anonymizer:", _anonymizer_mode)

# Opção A (recomendada): carregue um CSV próprio do seu trabalho/curso
# Descomente para usar upload direto no Colab:
# from google.colab import files
# up = files.upload()  # selecione seu arquivo .csv
# csv_name = list(up.keys())[0]
# df_raw = pd.read_csv(csv_name)

# Opção B: gerar um dataset sintético com PII para fins de demonstração
def gera_sintetico(n=200):
    rows = []
    for i in range(n):
        nome = fake.name()
        email = fake.email()
        cpf = fake.cpf()
        telefone = fake.phone_number()
        cidade = fake.city()
        idade = rng.integers(16, 75)
        salario = float(rng.normal(3500, 1200))  # pode ser negativo; corrigimos abaixo
        salario = max(1200.0, round(salario, 2))
        obs = f"{nome} comprou no cartão e ligou para {telefone}."
        rows.append(dict(
            id_cliente=i+1, nome=nome, email=email, cpf=cpf, telefone=telefone,
            cidade=cidade, idade=int(idade), salario=salario, observacoes=obs
        ))
    return pd.DataFrame(rows)

df_raw = gera_sintetico(300)
df_raw.head()

"""Diagnóstico rápido (quais colunas são sensíveis?)"""

print("Colunas:", list(df_raw.columns))
display(df_raw.sample(5, random_state=RANDOM_SEED))

# Classificação simplificada:
identificadores_diretos = ["nome", "email", "cpf", "telefone"]
quase_identificadores = ["idade", "cidade"]
sensiveis = []

print("\nIdentificadores diretos:", identificadores_diretos)
print("Quase-identificadores:", quase_identificadores)
print("Sensíveis:", sensiveis)

"""'Funções auxiliares de anonimização"""

# Pseudonimização (HMAC-SHA256 com SALT)
SALT = "troque_este_salt_com_a_sua_turma"

def pseudonimiza(valor: str) -> str:
    if pd.isna(valor):
        return valor
    if not isinstance(valor, str):
        valor = str(valor)
    key = SALT.encode()
    mac = hmac.new(key, valor.encode(), hashlib.sha256).hexdigest()
    return mac[:12]  # curto para visualização;

# Generalização (faixas) — mantemos idade por bins fixos e salário por quantis (leve mudança)
IDADE_BINS = [0, 17, 24, 34, 44, 54, 64, 120]
IDADE_LABELS = ["0-17","18-24","25-34","35-44","45-54","55-64","65+"]

def generaliza_idade(s):
    return pd.cut(s, bins=IDADE_BINS, labels=IDADE_LABELS, include_lowest=True, right=True)

def generaliza_salario_quantis(s, q=5):
    # qcut faz discretização por quantis — mudança leve vs. bins fixos, preservando utilidade agregada
    try:
        out = pd.qcut(s, q=q, duplicates="drop")
        return out.astype(str)
    except Exception:
        return s  # fallback

# Anonimização de texto livre usando text-anonymizer
def anonimiza_texto_livre(txt: str) -> str:
    if pd.isna(txt):
        return txt
    if _anonymizer_mode == "class":
        an = Anonymizer()
        return an.anonymize_text(txt)
    elif _anonymizer_mode == "function":
        return _anonymize_fn(txt)
    else:
        # fallback simples: mascara dígitos
        return "".join("x" if ch.isdigit() else ch for ch in txt)

"""## Aplicar de anonimização"""

df = df_raw.copy()

#  Remoção/Supressão de identificadores diretos
cols_remover = ["email", "cpf", "telefone"]  # mantemos 'nome' para pseudonimizar antes
df["nome_pseudo"] = df["nome"].apply(pseudonimiza)
df = df.drop(columns=["nome"])
df = df.drop(columns=cols_remover)

#  Generalização de quase-identificadores
df["faixa_idade"] = generaliza_idade(df["idade"]).astype(str)
df["salario_faixa"] = generaliza_salario_quantis(df["salario"], q=5)

#  Anonimização de texto livre em 'observacoes'
df["observacoes_anon"] = df["observacoes"].apply(anonimiza_texto_livre)
df = df.drop(columns=["observacoes"])  # após anonimizar, removemos o original para reduzir risco

#  Pequena perturbação numérica (leve ruído)
rs = np.random.RandomState(RANDOM_SEED)
df["salario_perturbado"] = (df_raw["salario"] * (1 + rs.normal(0, 0.03, size=len(df)))).round(2)

print("OK: técnicas aplicadas.")
display(df.head(3))

"""## Verificações simples de risco (**k‑anonymity** aproximado) e utilidade"""

# k-anonymity aproximado com QIDs escolhidos
QIDS = ["faixa_idade", "cidade"]
grp = df.groupby(QIDS).size().reset_index(name="n")
k = 3
pct_ok = (grp["n"] >= k).mean()
print(f"k-anonymity (k>={k}) em {pct_ok*100:.1f}% dos grupos. Grupos raros (n<k) devem ser avaliados.")

# Utilidade: média de salário antes e depois por cidade para conferir estabilidade
util = pd.DataFrame({
    "media_salario_raw": df_raw.groupby("cidade")["salario"].mean(),
    "media_salario_perturbado": df.groupby("cidade")["salario_perturbado"].mean()
}).dropna()
util.head(8)

df.to_parquet("dados_anonimizados.parquet")
df.sample(20, random_state=RANDOM_SEED).to_csv("amostra_anon.csv", index=False)

print("Arquivos salvos:")
print("- dados_anonimizados.parquet")
print("- amostra_anon.csv")